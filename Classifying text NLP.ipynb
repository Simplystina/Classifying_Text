{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I had to use the try and except block to catch the exception\n",
    "\n",
    "import json\n",
    "from itertools import count\n",
    "reviews = []\n",
    "with open(r'C:\\Users\\Stina\\Documents\\LEARNING PYTHON\\My data for data science\\All_Beauty_5.json') as f:\n",
    "\n",
    "    for i in f:\n",
    "        revf = json.loads(i)\n",
    "        try:\n",
    "            reviews.append((revf['reviewText'],revf['overall']))\n",
    "        except KeyError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function helps to get the sentiment score of each score\n",
    "\n",
    "def get_sentiment(score):\n",
    "    if score <= 2:\n",
    "        return 'Negative'\n",
    "    elif score == 3:\n",
    "        return 'Neutral'\n",
    "    elif score >3:\n",
    "        return 'Positive'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the x and y values\n",
    "# x is the reviews\n",
    "# y is the sentiment\n",
    "\n",
    "y=[get_sentiment(reviews[i][1]) for i in range(len(reviews))]\n",
    "x=[reviews[i][0] for i in range(len(reviews))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=True,shuffle=True)\n",
    "vect = CountVectorizer()\n",
    "vect_words=vect.fit_transform(x_train) #This learns the vocabulary of the data and transforms it into an array\n",
    "\n",
    "#This transforms the x_test data into an array using the vocabulary learnt from the x_train\n",
    "test_x = vect.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3948x5381 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 105593 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning the y_data to a numeric data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le=preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90        43\n",
      "           1       0.70      0.61      0.65        23\n",
      "           2       0.99      0.99      0.99      1250\n",
      "\n",
      "    accuracy                           0.98      1316\n",
      "   macro avg       0.86      0.84      0.85      1316\n",
      "weighted avg       0.98      0.98      0.98      1316\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9825227963525835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(vect_words,y_train)\n",
    "y_pred=clf_dec.predict(test_x)\n",
    "clf_dec.score(test_x,y_test)  #This gives the accuracy of the model\n",
    "print(metrics.classification_report(y_test,y_pred)) #This gives the report of all\n",
    "metrics.accuracy_score(y_test,y_pred)  #This gives the accuracy of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986322188449848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        43\n",
      "           1       0.83      0.65      0.73        23\n",
      "           2       0.99      1.00      0.99      1250\n",
      "\n",
      "    accuracy                           0.99      1316\n",
      "   macro avg       0.91      0.85      0.88      1316\n",
      "weighted avg       0.99      0.99      0.99      1316\n",
      "\n",
      "0.986322188449848\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(kernel = 'linear',degree = 2)\n",
    "clf_svm.fit(vect_words,y_train)\n",
    "y_pred=clf_svm.predict(test_x)\n",
    "print(clf_svm.score(test_x,y_test)) #This gives the accuracy of the model\n",
    "print(metrics.classification_report(y_test,y_pred)) #This gives the report of all metrics\n",
    "print(metrics.accuracy_score(y_test,y_pred)) #This gives the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbb = xgb.XGBClassifier(random_state=5,learning_rate=0.1,n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=xgbb.fit(vect_words,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893617021276596"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,mode.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I tried 3 models and a xgboost boosting algorithm gave the highest prediction of 0.989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
